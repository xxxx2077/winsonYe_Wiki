# 八股

## MySQL是如何存储数据

MySQL默认使用Innodb引擎，所以介绍Innodb的存储方式

MySQL数据库存储在/var/lib/mysql目录下，例如my_test_db路径为/var/lib/mysql/my_test_db

数据库中的表以文件的方式存储：

- 表名.frm存储表结构
- 表名.ibd存储表数据

### 表空间存储结构

一张表空间的分布：

- 行：表中的每一行记录以行格式存储
- 页：数据库读写单位不是行，而是页。一个数据页包含若干个行。
  - **一个数据页的大小通常为16KB**。
  - **数据页以双向链表的方式组织**
  - **由于存在大量数据页，需要使用目录进行快速检索，因此为数据页建立了基于B+树的索引，也就是聚簇索引**
- 区：B+树中每一层的数据页以双向链表的方式连接在一起。当数据量很大的时候，如果以数据页为单位分配内存，会导致相邻的数据页分配在离散的空间，这会导致随机IO读写，性能非常低。而顺序IO读写性能会高很多，为了追求顺序IO，我们将连续的数据页分配在连续的空间，这么一个连续的空间就是「区」。
  - **一个区大小通常为1MB，即一个区能容纳64个页**
- 段：一张表由多个段组成，每个段存储多个区
  - 索引段：存储B+树的非叶子节点的区的集合
  - 数据段：存储B+树的叶子节点的区的集合
  - 回滚段：存储回滚数据的区的集合

### B+树的存储结构（数据页是如何存储数据行）

innodb的索引都按B+树存储，可以分为[聚簇索引和二级索引](#聚簇索引和二级索引)

这里只讨论聚簇索引

#### 单个数据页的存储结构

每个数据页存储若干行，数据页的结构为：
- 文件头
- 页头
- **最小记录和最大记录**
- **行记录**
- **页目录**
- 文件尾

![picture 0](assets_IMG/xxx/IMG_20250413-160942421.png)  

数据页的组织方式为「双向链表」

![picture 1](assets_IMG/xxx/IMG_20250413-161030241.png)  

数据页内使用页目录作为索引，快速找到存储的行记录。具体来说：

- 行目录按照主键排序，通过指针相连，为单链表
- 行记录被分为了多个组，每个组最后一个记录就是最大的记录。第一个记录组存储数据页的最小记录，最后一个记录组存储数据页的最大记录。
- 页目录存储若干个槽，每个槽对应一个记录组，槽的值为记录组中最大记录（最后一个记录）

![picture 2](assets_IMG/xxx/IMG_20250413-161743128.png)  

查找过程就是通过页目录二分查找，比较目标主键值和槽的值。

#### 多个数据页之间的存储结构

为了快速检索大量的数据页，使用B+树作为索引，快速查询数据页

在B+树中，每个节点都是一个数据页，同层节点数据页使用双向链表相连，从而方便范围查询

非叶子节点分为多层，从而减小每层的搜索量

只有叶子节点存储数据，非叶子节点存储页号
（[为什么MySQL使用B+树](#为什么mysql使用b树)）

### 聚簇索引和二级索引

聚簇索引：B+树叶子节点的值存储实际数据
二级索引：B+树叶子节点的值存储主键值

如果查询二级索引的值不是目标值，则需要「回表」：带着叶子节点存储的主键值回到聚簇索引树进行查找，最终得到实际数据（需要查询两次B+树）

如果查询二级索引的值就是目标值，我们称之为「覆盖索引」（只需要查询一次B+树）

### 为什么MySQL使用B+树

二分查找树不平衡，容易变成链表

平衡查找树层数高，磁盘IO次数多 & 平衡操作复杂度高

#### 和B树相比

1. 尽管B树单点平均查询时间更短（非叶子节点存储数据），但是B+树非叶子节点不存储数据，因此能够存储更多的索引，相同数据量树的层数更矮，树的层数对应磁盘IO次数，因此磁盘IO次数更少
2. B+树引入了冗余节点（非叶子节点不存储数据），因此插入和删除不涉及复杂的树的变形，插入和删除效率更高
3. 双向链表使得范围查询效率更高

## redo log是什么

Buffer Pool的数据存在内存，容易丢失，因此需要持久化。redo log是MySQL持久化Buffer Pool数据的方法

MySQL持久化方式：

1. 执行更新操作时，先记录更新前的数据到undo log中，undo log也会写入到Buffer Pool的undo页。由于对Buffer Pool的物理页进行了修改，因此redo log会记录undo log的变更。
2. 之后执行更新操作：对Buffer Pool的缓存页进行更新，将其标记为脏页。
3. 将本次操作「对Buffer Pool的缓存页进行更新」记录在redo log中
4. 刷盘：后台线程在某个时间将Buffer Pool的脏页刷新到磁盘中

一次更新操作，redo log不仅记录了数据页的变更，也记录了undo页的变更

以上为WAL（Write Ahead Logging）技术：写操作不是立即写到磁盘上，而是先写到日志，在合适的时间再写到磁盘。

redo log记录物理页做了什么修改，基于WAL技术，事务提交的时候只需要将redo log持久化，不需要持久化脏页。

由于redo log已经持久化，因此即使脏页数据丢失，根据redo log仍然能恢复数据。

redo log仅仅在事务提交之后数据丢失的时候使用，事务未提交修改的数据没有意义，直接通过undo log回滚。

### redo log要写到磁盘，数据也要磁盘，redo log的意义在哪？

数据写到磁盘是随机写，而redo log是追加写到文件中，属于顺序写。顺序写性能更高

另外，redo log提供了持久化数据的能力。

### redo log刷盘方式

本地维护redo log buffer，每产生一条redo log，先写到redo log buffer，再持久化到磁盘

### redo log什么时候刷盘

- MySQL正常关闭
- redo log buffer写入量大于redo log buffer内存空间一半
- 后台线程每隔一秒将redo log写入到磁盘
- 事务提交时

### redo log文件写满了怎么办

innodb维护一个redo log group，包含两个redo log文件，每个redo log大小一致

redo log group将两个redo log文件组织为一个环状，即「循环写」

为什么设计为环状？这是因为刷盘之后redo log就没用了，因此我们可以将其擦除。这也代表了redo log能够被覆盖。

## 为什么需要Buffer Pool

磁盘查询效率慢，因此在内存引入缓存Buffer Pool

[MySQL如何存储数据](#mysql是如何存储数据)提到MySQL存储单位为数据页，Buffer Pool读写单位也是数据页，每个数据页大小为16KB

初始化Buffer Pool时，数据页为空，不映射具体的物理内存，当使用数据页的时候才发生「缺页异常」，填写页表（虚拟内存与物理内存映射关系）

- 读取数据页：先读Buffer Pool，再读磁盘
- 写数据页：如果数据页在Buffer Pool，直接修改Buffer Pool上的数据页，将其标记为脏页。为了减少磁盘IO，不会立即将脏页写入磁盘，而是由后台线程选择合适的时机将其写入磁盘（刷盘）

## 缓存（Redis）和数据库（MySQL）如何保证一致性

### 采用哪两种操作组合

更新数据库再更新缓存 or 更新缓存再更新数据库 or 删除缓存再更新数据库  -> 导致数据不一致

**采取「先更新数据库再删除缓存」的方案：**

- 这是因为更新数据库时间与缓存读写相比更长，很大概率在事务A更新数据库的过程，其他事务已经完成了读写缓存的操作，那么事务A完成更新数据库再删除缓存，就能让后面的事务无法再读取旧值，从而实现一致性。
- 缺点：每次更新数据都要删除缓存，对缓存命中率产生影响。如果追求缓存命中率，需要采用「先更新数据库再更新缓存」的方案

最好再给缓存数据加上过期时间兜底。

!!! tip "More details"

    更新缓存再更新数据库 or 删除缓存再更新数据库 两张方案的问题在于忽视了数据库与缓存读写速度的差异。

    「先更新数据库再删除缓存」不能保证强一致性，毕竟更新数据库的过程也有其他事务能够读取缓存的旧值，但是能够实现最终一致性。

!!! note "同样是先更新数据库再对缓存操作，为什么「先更新数据库再更新缓存」不行？" 
    
    1. 白费服务端资源。cache中的数据可能由服务端经过大量计算得到，如果频繁修改db，就需要频繁更新cache，并且更新的cache数据可能都不会被访问到，服务端的计算白做了，就会浪费服务端资源。
    2. 更新缓存不一致概率更大。因为删除缓存是幂等操作，两个事务无论什么顺序删除缓存，结果都是缓存没了这条数据；而更新缓存不是幂等操作，缓存数据和更新顺序有关。

**采取「先更新数据库再更新缓存」的方案：**

1. 追求强一致性。保证更新缓存的时候只有一个请求，那么就不会产生并发问题，为此引入分布式锁，更新缓存的时候先加个分布式锁，但是会对写性能造成影响。
2. 允许缓存与数据库存在短期不一致的场景。为缓存数据设置过期时间，过期时间越短，数据一致性越高，缓存命中率越低。

!!! tip "为什么更新缓存的时候加锁，而不是更新数据库的时候加锁”

    假设有若干个事务更新数据库，无论他们之间并发的顺序如何，首先完成更新数据库的就会先拿到分布式锁，其他事务只能阻塞等待，等这个事务更新完缓存才会释放分布式锁。之后重复这个过程。

    以上分析我们可以知道，更新缓存时拿分布式锁的顺序，其实就是数据库更新值的顺序，因此保证了数据的一致性。

**采取「先更新缓存再更新数据库」的方案：**  延迟双删

![picture 0](assets_IMG/interview_question/IMG_20250413-190801350.png)  

### 如何保证两个操作都能执行成功

前面讨论的是两个操作都成功的情况，然而如果第二个操作失败，无论第二个操作是操作数据库还是缓存，都会导致数据不一致。因此解决思路就是如何保证两个操作都能执行成功。

两种方法本质思路都是对更新数据库后的数据进行存储，进行删除缓存。如果删除缓存失败，则多次重试。

删除缓存是异步操作的。

#### 消息队列重试法

1. 将删除缓存的数据加入到消息队列
2. 如果应用删除缓存失败，那么从消息队列中取出缓存数据重试「删除缓存」操作
3. 如果重试还是失败，那么再重试。直到重试次数用尽，向业务层发送报错消息。
4. 如果删除缓存成功，那么将数据从消息队列移除，避免重复操作

#### 订阅MySQL binlog 再操作缓存

由于binlog记录了MySQL所有数据操作，因此使用canal监听binlog可以获取数据的变更。

1. canal监听binlog
2. binlog日志放入消息队列中
3. 编写一个消费者程序，订阅消息队列中的binlog。当消费者接收到新的binlog，它根据日志中的更新信息执行相应的缓存删除操作
4. 如果成功删除缓存，则消费者向消息队列发送ack确认消息
5. 如果失败，则消息队列保留这条消息，继续重试。

!!! warning "如果先从消息队列取事件发ack再执行删除缓存操作"

    万一删除缓存失败，那么消息队列就会丢失消息，无法进行重试。

## 缓存满了怎么办

### 内存淘汰策略

1. 不淘汰数据。数据满了就不允许继续写入，但是可以查询和删除
2. 淘汰数据
   1. 在设置了过期时间的数据中淘汰
      1. 随机淘汰
      2. lru
      3. lfu
   2. 所有数据范围内淘汰
      1. 随机淘汰
      2. lru
      3. lfu

### 过期删除策略

「惰性删除」 + 「定期删除」

惰性删除：访问或删除某个key的时候，判断它是否过期，如果过期则删除；否则返回

定期删除：一定时间从数据库中随机抽取若干个key进行检查，删除其中的过期key

- 一定时间：通常指每秒十次
- 若干个：通常指抽20个，如果有5个以上，即超过25%过期，则继续抽取；直到定期删除时间到或者过期占比小于25%



## 集群

### 主从复制

单台服务器可能丢失数据 或者 宕机（短期内无法提供数据），为了保证高可用，需要多台服务器存储数据（副本）

主从复制保证了多台服务器数据的一致性

#### MySQl主从复制

binlog记录了数据库表数据和表结构的变更

1. 主库执行完更新操作，先写入binlog，再提交事务
2. 从库创建专门的IO线程，与主库的log dump线程创建连接，接收主库的binlog，把binlog写入到relay log中
3. 从库再创建一个SQL线程，读取relay log中的内容回放mysql数据，实现主从数据一致性。

#### Redis主从复制

全量同步：

阶段1: 建立连接，协商同步
1. 从服务器向主服务器发起全量同步请求（offset = -1）
2. 主服务器响应全量同步，从服务器保存主服务器信息

阶段2: 主服务器同步数据给从服务器
3. 主服务器生成rdb快照，发送给从服务器
4. 从服务器接收到rdb文件之后，清空数据，加载rdb文件中的数据

阶段3:主服务器发送新写命令给从服务器
5. 在rdb文件生成和传输期间，主服务器产生的写命令记录到replication backlog buffer中
6. 一旦rdb文件传输完成，主服务器会将replication backlog buffer中的命令发送到从服务器，从服务器执行这些命令，保证一致性

增量同步：

1. 从服务器向主服务器发起增量同步请求（offset 不等于 -1）
2. 主服务器收到命令，发送cotinue响应告诉从服务器采用增量同步
3. 主服务器将从服务器断线期间所执行的写命令发送给从服务器，从服务器执行这些命令

### 哨兵机制

Redis提供了一个哨兵节点机制，为了高可用，往往使用哨兵集群。

- 监控：哨兵节点作为观察者，时刻监视主从节点，方式为给所有节点发送心跳包。
  1. 如果某个节点没有响应，则该节点被哨兵节点主观下线
  2. 主观下线不代表这个节点故障，哨兵节点会询问其他哨兵节点，如果超过quorum数量的哨兵节点都认为主观下线，则该节点客观下线
- 选主：
  1. 如果客观下线的是从节点或者哨兵节点，那么操作结束。
  2. 如果客观下线的是主节点，那么需要选主。
  3. 首先需要在哨兵节点中选取“话事人”
     1. 每一个哨兵节点都可以成为“话事人”，并且每个哨兵节点判断主观下线之后，都会向其他节点“拉票”（请求将自己选举为“话事人”）
     2. 如果被请求的节点有票数（没有同意过其他哨兵节点的选举请求），则票数+1；否则不同意
     3. 如果一个哨兵节点获得的选举票数满足条件（quorum和哨兵节点数/2 + 1的最大值），则将哨兵节点选举为“话事人”；否则重新选举。
  4. 选举出“话事人”后，由“话事人”在从节点中选出一个节点作为主节点
    1. “身体好的”（过滤故障的节点）
    2. “最服从的”（选举优先级高的）
    3. “进度与主节点最接近的”（复制偏移量最大的）
    4. “随便选了”（选择runid最小的，runid是随机生成的）

### 数据分片

高性能：数据分片将数据分散到多个节点，提高读写性能和吞吐量
高可用：集群避免单点挂掉

#### MySQL 数据分片

其实就是水平分表 & 水平分库，把一张表比如说按照id区间拆成多个数据分片，这一步是水平分表；接着将分片分散在不同的数据库，这一步是水平分库。

水平分表能够减小一张表的数据量，水平分库能够减小单点压力。

#### Redis 数据分片

Redis Cluster采取哈希槽处理数据和节点的映射关系。

一个切片集群一共有16384个哈希槽，按照节点数量，哈希槽按照不同策略分配

- 平均分配，每个节点分到哈希槽的个数为 16384/节点个数
- 手动分配，人工指定

如何判断数据到哪个哈希槽？

1. 根据key计算一个16bit的值
2. 这个16bit的值对16384（槽的总数）取余，得到哈希槽值。

### 冷热分离

#### 什么是热key

经常被请求的key

#### 如何解决热key问题

1. 对热key进行复制并迁移到其他数据分片
2. 采用读写分离架构